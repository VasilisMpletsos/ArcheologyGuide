{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LLM with a text2speech output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\awesome\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, pipeline\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove with regex the brackets and its content from a phrase\n",
    "def clean_text(text):\n",
    "    # strip sentenece\n",
    "    text = text.lower().strip()\n",
    "    # remove tabs\n",
    "    text = text.replace('\\t', '')\n",
    "    # remove new lines\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_data = read_txt_file('./knowledge base/Sanctuary of the Middle Plateau/building 1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator = \".\",\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap  = 150,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 301, which is longer than the specified 300\n",
      "Created a chunk of size 349, which is longer than the specified 300\n",
      "Created a chunk of size 551, which is longer than the specified 300\n"
     ]
    }
   ],
   "source": [
    "building_passages = text_splitter.create_documents([building_data]);\n",
    "building_passages = [clean_text(sentence.page_content) for sentence in building_passages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the southernmost one (building 1) is a cult building in which, based on the sculptures and inscriptions that emerged from both the interior of the building and the adjacent reservoir, the worship of the god asklepios and the goddess aphrodite was housed',\n",
       " 'it is possible that the building also housed the worship of the samothracian gods, based on an inscribed stele found embedded in a newer building',\n",
       " 'it is an oblong building with dimensions of seventeen point fourty Ã— eleven point fifty meters, made of slate, which consists of two independent rooms opening to the east on a doric portico, from which the building was accessed',\n",
       " 'it is erected on a strong rise in the west, with a maximum surviving height of two point eighty meters. the walls of the building were plastered with red mortar which survives its original placement in some places, both internally and externally',\n",
       " 'the walls of the building were plastered with red mortar which survives its original placement in some places, both internally and externally.regarding the internal layout of the rooms, the northernmost room preserves a large part of the pebbled floor',\n",
       " 'regarding the internal layout of the rooms, the northernmost room preserves a large part of the pebbled floor. in contact with the wall on the north-east side, a three-meter raised strip is also preserved, consisting of smaller pebbles',\n",
       " 'according to the excavator, the different configuration of the pebbles in contact with the wall is a clear indication of the placement of couches around the perimeter of the walls, possibly for holding dinners or for sleeping',\n",
       " 'the smaller space c preserves the foundation of a pedestal, measuring one twenty x zero eighty meters, probably intended to support a cult statue',\n",
       " 'the doric portico, which in its original phase was single, was divided, or more likely abolished, in roman times by the construction of a transverse wall, aligned with the intermediate wall of rooms a and c, changing the layout of the building and by extension dividing the in two separate buildings',\n",
       " 'in contact with the pilaster, in the southeast corner of the building is the opening of the ugly water tank, carved into the natural rock',\n",
       " 'the filling of the tank was achieved through an overflow channel, which connected the tank to the collector (one twenty meters deep and one meter in diameter) located south and in contact with that of the tank',\n",
       " 'the water was directed from the roof to the collector and ended up in the tank through a pipe. the interior of both the collector and the tank was covered with hydraulic mortar, making the tank watertight',\n",
       " 'the proximity of the reservoir to the building attests to the inseparable relationship between the two and that the water collected was intended for the needs of the sanctuary, while the collector could also serve as a purification tank',\n",
       " 'at the same time, important finds came from the tank, such as a marble head of asclepius from the late hellenistic period, as well as an inscribed colonnade of the first second century, dedicated to asclepius by a certain callisto, while fragments of marble child figurines came from, a category of votives found in sanctuaries of the god asclepius',\n",
       " 'also collected were a small head of aphrodite from the hellenistic period, and a clay head of demeter from a large figurine from the late classical period',\n",
       " 'remarkable, finally, is the presence within the reservoir, towards the deeper layers of the excavated embankment, two human femurs whose dating has not yet been determined',\n",
       " 'in addition to the finds from the interior of the cistern, findings such as a votive inscription to aphrodite syria, built into the intermediate wall of building one in second use, a marble statue of aphrodite and the lower part of a marble female of a statue that had been found a short distance lower than buildings one and two, and probably belonged according to panagiotis themelis to the colossal statue of aphrodite in the anadyomeni type, which was crafted by the messenian sculptor damophon i make clear the co-cult of asclepius and aphrodite']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "similarity_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "similarity_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = df.question.to_list()\n",
    "# Tokenize sentences\n",
    "encoded_input = similarity_tokenizer(building_passages, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = similarity_model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "sentence_embeddings = sentence_embeddings.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "speech_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cmu-arctic-xvectors (C:/Users/User/.cache/huggingface/datasets/Matthijs___cmu-arctic-xvectors/default/0.0.1/a62fea1f9415e240301ea0042ffad2a3aadf4d1caa7f9a8d9512d631723e781f)\n"
     ]
    }
   ],
   "source": [
    "# load xvector containing speaker's voice characteristics from a dataset\n",
    "speaker_voice = 2933\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[speaker_voice][\"xvector\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_text = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = [text.split(\" \") for text in building_passages]\n",
    "bm25 = BM25Okapi(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Did aphrodite was worshiped there?\n",
      "------------- Similarity NN -------------\n",
      "Similarity score: 58.49%\n",
      "Top answer: in addition to the finds from the interior of the cistern, findings such as a votive inscription to aphrodite syria, built into the intermediate wall of building one in second use, a marble statue of aphrodite and the lower part of a marble female of a statue that had been found a short distance lower than buildings one and two, and probably belonged according to panagiotis themelis to the colossal statue of aphrodite in the anadyomeni type, which was crafted by the messenian sculptor damophon i make clear the co-cult of asclepius and aphrodite\n",
      "------------- Similarity BM25 -------------\n",
      "Similarity score: 2.23576365326113\n",
      "Top answer: in addition to the finds from the interior of the cistern, findings such as a votive inscription to aphrodite syria, built into the intermediate wall of building one in second use, a marble statue of aphrodite and the lower part of a marble female of a statue that had been found a short distance lower than buildings one and two, and probably belonged according to panagiotis themelis to the colossal statue of aphrodite in the anadyomeni type, which was crafted by the messenian sculptor damophon i make clear the co-cult of asclepius and aphrodite\n"
     ]
    }
   ],
   "source": [
    "query = \"Did aphrodite was worshiped there?\"\n",
    "tokenized_query = similarity_tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "embedded_query = similarity_model(**tokenized_query)\n",
    "question_embedding = mean_pooling(embedded_query, tokenized_query['attention_mask'])\n",
    "question_embedding = question_embedding.detach().numpy()\n",
    "scores = cosine_similarity([question_embedding[0]], sentence_embeddings)[0]\n",
    "max_pos = np.argmax(scores[1:])\n",
    "max_score = scores[max_pos+1]\n",
    "candidate_answer = building_passages[max_pos+1]\n",
    "\n",
    "tokenized_query = query.split(\" \")\n",
    "answer_scores = bm25.get_scores(tokenized_query)\n",
    "max_score_bm25 = answer_scores.max()\n",
    "top_answer = bm25.get_top_n(tokenized_query, building_passages, n=1)[0]\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print('------------- Similarity NN -------------')\n",
    "print(f\"Similarity score: {max_score*100:.2f}%\")\n",
    "print(f\"Top answer: {candidate_answer}\")\n",
    "print('------------- Similarity BM25 -------------')\n",
    "print(f\"Similarity score: {max_score_bm25}\")\n",
    "print(f\"Top answer: {top_answer}\")\n",
    "\n",
    "if max_score < 0.5:\n",
    "    candidate_answer = 'I am sorry, I do not know the answer to that question.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=candidate_answer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = speech_model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

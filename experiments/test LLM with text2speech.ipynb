{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into csv rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove with regex the brackets and its content from a phrase\n",
    "def clean_text(text):\n",
    "    # strip sentenece\n",
    "    text = text.lower().strip()\n",
    "    # remove tabs\n",
    "    text = text.replace('\\t', '')\n",
    "    # remove new lines\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = read_txt_file('./KnowledgeBase/Sanctuary_of_the_Middle_Plateau/building5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator = \".\",\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 50,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 361, which is longer than the specified 150\n",
      "Created a chunk of size 453, which is longer than the specified 150\n",
      "Created a chunk of size 166, which is longer than the specified 150\n",
      "Created a chunk of size 274, which is longer than the specified 150\n",
      "Created a chunk of size 181, which is longer than the specified 150\n",
      "Created a chunk of size 257, which is longer than the specified 150\n",
      "Created a chunk of size 340, which is longer than the specified 150\n"
     ]
    }
   ],
   "source": [
    "passages = text_splitter.create_documents([item_data]);\n",
    "passages = [clean_text(sentence.page_content) for sentence in passages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in addition to the buildings connected with the religious life of the city, an important public building that came to light is the building complex that was revealed on the northwest side of the middle plateau, on the plateau that develops lower than the archaic temple (building three) to the west, where it was probably located the market of hellenistic times',\n",
       " 'it is a two-story building of the late classical period, measuring seventeen by ten meters. it presents at least two main architectural phases',\n",
       " 'the oldest dates back to around the middle of the fourth century',\n",
       " 'the building seems to have suffered some destruction and significant repair during the hellenistic period, probably in the second century',\n",
       " 'a monumental staircase in the middle of the building led to the first floor, where the apparently official apartments were located: room a with the liturgical hearth, the b-c with paved floor (and partly shaped natural rock) probably used for meals, north west room g whose use remains unknown (it survived at a level below the floor) and a series of rooms that must have had wooden floors, above spaces d and h, south of the scale and f-t, north of it',\n",
       " 'room f seems to have been the place where most of the utensils and objects related to the use of the building were kept',\n",
       " 'this is also where the food preparation must have taken place',\n",
       " 'after all, as we mentioned above, room f communicated with the upper floor, where the official rooms of the public building must have been, by the internal staircase',\n",
       " 'the small underground room h was certainly a storeroom (of pitheons?)',\n",
       " 'access here must have been through a hatch in the wooden floor of the first floor',\n",
       " 'room d seems to have been a storage room as well, and in the first phase it may have communicated with room h, with an opening in its ne corner',\n",
       " 'it is not excluded that d also communicated with room e and the staircase, if we accept that wall t thirteen is a later addition when it was decided after the first disaster that the building suffered to fill the room with soil that contained almost all its contents room f',\n",
       " 'the south east hall was paved, while a hearth was found in the northeast',\n",
       " 'we assume that it is a building of a public, perhaps even commercial character, while the construction in the middle of the north-eastern room seems to have had a religious purpose',\n",
       " 'perhaps it is the sacred hearth, where the goddess hestia is worshiped and burns an unquenchable flame of the city',\n",
       " 'the findings allow the building to be dated to the classical period, although the presence of numerous finds from the hellenistic period in the immediate embankments of the building probably indicate the use of the building during hellenistic times as well',\n",
       " 'the possible public character of building five combined with the findings of the adjacent monumental analemma four do not rule out the version that in this area was the sought-after agora of the ancient city of kythnos and the building is probably identified with its rectory, while it is not excluded that it is identified with market law']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({'passages': passages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./KnowledgeBase/Sanctuary_of_the_Middle_Plateau/building5_passages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Loaded Similarity Model\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "similarity_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "similarity_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print('INFO:     Loaded Similarity Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "building1_passages = pd.read_csv('../data/building1_passages.csv')['passages'].to_list()\n",
    "building2_passages = pd.read_csv('../data/building2_passages.csv')['passages'].to_list()\n",
    "building3_passages = pd.read_csv('../data/building3_passages.csv')['passages'].to_list()\n",
    "building5_passages = pd.read_csv('../data/building5_passages.csv')['passages'].to_list()\n",
    "\n",
    "building_passages = [building1_passages, building2_passages, building3_passages, building5_passages]\n",
    "building_embeddings = []\n",
    "for i, passages in enumerate(building_passages):\n",
    "    encoded_input = similarity_tokenizer(building_passages[i], padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = similarity_model(**encoded_input)\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    building_embeddings.append(embeddings.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11622969,  0.03409467,  0.05019226, ...,  0.05629298,\n",
       "         0.11818867,  0.02524624],\n",
       "       [-0.11978338,  0.40054923, -0.1928807 , ...,  0.07970957,\n",
       "         0.32337907,  0.02805086],\n",
       "       [ 0.38470966,  0.06254954,  0.06127506, ...,  0.5766263 ,\n",
       "        -0.35689756, -0.12071333],\n",
       "       ...,\n",
       "       [-0.021469  ,  0.2774418 ,  0.11278592, ..., -0.01957736,\n",
       "        -0.28363362,  0.17731604],\n",
       "       [ 0.27422208,  0.22551264,  0.19516474, ...,  0.02150778,\n",
       "        -0.09390647, -0.00687842],\n",
       "       [-0.23764972,  0.19658478, -0.49915496, ...,  0.04694569,\n",
       "         0.15331982, -0.00156602]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buildings one and two seem to be dated to the late classical to early hellenistic times, a period where there seems to be a plan to commemorate the upper city, with the construction of monumental buildings'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"To when it is dated?\"\n",
    "tokenized_query = similarity_tokenizer(question, padding=True, truncation=True, return_tensors='pt')\n",
    "embedded_query = similarity_model(**tokenized_query)\n",
    "question_embedding = mean_pooling(embedded_query, tokenized_query['attention_mask'])\n",
    "question_embedding = question_embedding.detach().numpy()\n",
    "similarities = cosine_similarity(question_embedding, building_embeddings[1])\n",
    "most_similar_passage_index = np.argmax(similarities)\n",
    "building_passages[1][most_similar_passage_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14941174"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into csv rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmpletsos\\Anaconda3\\envs\\guide\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove with regex the brackets and its content from a phrase\n",
    "def clean_text(text):\n",
    "    # strip sentenece\n",
    "    text = text.lower().strip()\n",
    "    # remove tabs\n",
    "    text = text.replace('\\t', '')\n",
    "    # remove new lines\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read txt file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(    \n",
    "    separator = \".\",\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 50,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 166, which is longer than the specified 150\n",
      "Created a chunk of size 160, which is longer than the specified 150\n",
      "Created a chunk of size 207, which is longer than the specified 150\n",
      "Created a chunk of size 197, which is longer than the specified 150\n",
      "Created a chunk of size 223, which is longer than the specified 150\n",
      "Created a chunk of size 284, which is longer than the specified 150\n",
      "Created a chunk of size 219, which is longer than the specified 150\n",
      "Created a chunk of size 204, which is longer than the specified 150\n",
      "Created a chunk of size 255, which is longer than the specified 150\n",
      "Created a chunk of size 228, which is longer than the specified 150\n",
      "Created a chunk of size 227, which is longer than the specified 150\n",
      "Created a chunk of size 301, which is longer than the specified 150\n",
      "Created a chunk of size 211, which is longer than the specified 150\n",
      "Created a chunk of size 238, which is longer than the specified 150\n",
      "Created a chunk of size 349, which is longer than the specified 150\n",
      "Created a chunk of size 156, which is longer than the specified 150\n",
      "Created a chunk of size 173, which is longer than the specified 150\n",
      "Created a chunk of size 551, which is longer than the specified 150\n",
      "Created a chunk of size 319, which is longer than the specified 150\n",
      "Created a chunk of size 191, which is longer than the specified 150\n",
      "Created a chunk of size 170, which is longer than the specified 150\n",
      "Created a chunk of size 323, which is longer than the specified 150\n",
      "Created a chunk of size 206, which is longer than the specified 150\n",
      "Created a chunk of size 169, which is longer than the specified 150\n",
      "Created a chunk of size 152, which is longer than the specified 150\n",
      "Created a chunk of size 277, which is longer than the specified 150\n",
      "Created a chunk of size 234, which is longer than the specified 150\n",
      "Created a chunk of size 425, which is longer than the specified 150\n",
      "Created a chunk of size 179, which is longer than the specified 150\n",
      "Created a chunk of size 239, which is longer than the specified 150\n",
      "Created a chunk of size 162, which is longer than the specified 150\n",
      "Created a chunk of size 160, which is longer than the specified 150\n",
      "Created a chunk of size 231, which is longer than the specified 150\n",
      "Created a chunk of size 221, which is longer than the specified 150\n",
      "Created a chunk of size 239, which is longer than the specified 150\n",
      "Created a chunk of size 196, which is longer than the specified 150\n",
      "Created a chunk of size 262, which is longer than the specified 150\n",
      "Created a chunk of size 300, which is longer than the specified 150\n",
      "Created a chunk of size 361, which is longer than the specified 150\n",
      "Created a chunk of size 457, which is longer than the specified 150\n",
      "Created a chunk of size 166, which is longer than the specified 150\n",
      "Created a chunk of size 274, which is longer than the specified 150\n",
      "Created a chunk of size 181, which is longer than the specified 150\n",
      "Created a chunk of size 257, which is longer than the specified 150\n",
      "Created a chunk of size 340, which is longer than the specified 150\n",
      "Created a chunk of size 177, which is longer than the specified 150\n",
      "Created a chunk of size 165, which is longer than the specified 150\n",
      "Created a chunk of size 221, which is longer than the specified 150\n",
      "Created a chunk of size 169, which is longer than the specified 150\n",
      "Created a chunk of size 248, which is longer than the specified 150\n",
      "Created a chunk of size 168, which is longer than the specified 150\n",
      "Created a chunk of size 166, which is longer than the specified 150\n",
      "Created a chunk of size 208, which is longer than the specified 150\n",
      "Created a chunk of size 179, which is longer than the specified 150\n",
      "Created a chunk of size 189, which is longer than the specified 150\n",
      "Created a chunk of size 272, which is longer than the specified 150\n",
      "Created a chunk of size 215, which is longer than the specified 150\n",
      "Created a chunk of size 212, which is longer than the specified 150\n",
      "Created a chunk of size 273, which is longer than the specified 150\n",
      "Created a chunk of size 474, which is longer than the specified 150\n",
      "Created a chunk of size 290, which is longer than the specified 150\n",
      "Created a chunk of size 173, which is longer than the specified 150\n",
      "Created a chunk of size 264, which is longer than the specified 150\n",
      "Created a chunk of size 279, which is longer than the specified 150\n",
      "Created a chunk of size 225, which is longer than the specified 150\n",
      "Created a chunk of size 367, which is longer than the specified 150\n",
      "Created a chunk of size 258, which is longer than the specified 150\n",
      "Created a chunk of size 246, which is longer than the specified 150\n",
      "Created a chunk of size 167, which is longer than the specified 150\n",
      "Created a chunk of size 240, which is longer than the specified 150\n",
      "Created a chunk of size 216, which is longer than the specified 150\n",
      "Created a chunk of size 293, which is longer than the specified 150\n",
      "Created a chunk of size 168, which is longer than the specified 150\n"
     ]
    }
   ],
   "source": [
    "# Os walk through the knowledge base folder\n",
    "for root, dirs, files in os.walk(\"./KnowledgeBase/\"):\n",
    "    for file in files:\n",
    "        # if it is txt\n",
    "        if file.endswith(\".txt\"):\n",
    "            filename = file.split('.txt')[0]\n",
    "            item_data = read_txt_file(os.path.join(root, file))\n",
    "            passages = text_splitter.create_documents([item_data]);\n",
    "            passages = [clean_text(sentence.page_content) for sentence in passages]\n",
    "            # create dataframe\n",
    "            df = pd.DataFrame({'passages': passages})\n",
    "            df.to_csv(f'../data/{filename}_passages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = read_txt_file('./KnowledgeBase/South_Structures/necropolis.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 168, which is longer than the specified 150\n",
      "Created a chunk of size 166, which is longer than the specified 150\n",
      "Created a chunk of size 208, which is longer than the specified 150\n",
      "Created a chunk of size 179, which is longer than the specified 150\n",
      "Created a chunk of size 189, which is longer than the specified 150\n"
     ]
    }
   ],
   "source": [
    "passages = text_splitter.create_documents([item_data]);\n",
    "passages = [clean_text(sentence.page_content) for sentence in passages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the ancient city had two necropolises outside the walls',\n",
       " 'the main cemetery of the ancient city occupies a large area outside the southern part of the wall, while groups of tombs can also be seen outside the northwestern gate',\n",
       " 'from the excavations of the years from one thousand ninty one to ninty six, to an area of approximately four hundred square meter sixty eight (68) burials were found',\n",
       " 'out of the 68 burials that came to light, 62 were found arrested and only 6 unclaimed',\n",
       " \"out of the total number of graves, 41 definitely belong to adults, 17 graves that were found very damaged seem to have belonged to adults as well, while only 8 of the total were children's and two of infants\",\n",
       " 'few skeletons are preserved in good condition, so it is difficult to identify the sex and age of the individuals',\n",
       " \"of the total number of graves, 66 are box-shaped carved into the natural rock and there is only one inhumation in a sharp-bottomed amphora, although a child's burial in a beehive\",\n",
       " 'the graves were carved densely and almost parallel to each other on the downhill slope of the diocese',\n",
       " 'from the fragments of vessels recovered from most of the burials it appears that almost all the graves were endowed',\n",
       " 'the usual grave offerings were vessels, and these are mainly vessels of small size, such as olpes, lekythia and incense containers, but also drinking vessels, such as kyathia and scyphidia',\n",
       " 'the most common grave goods are lamps, which were found in all the box-shaped undisturbed graves.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({'passages': passages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./KnowledgeBase/South_Structures/necropolis_passages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
